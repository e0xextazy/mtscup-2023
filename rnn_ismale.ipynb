{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "945431b6-3f7e-48a0-8df2-512825b639c2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import gc\n",
    "import warnings\n",
    "os.environ['OPENBLAS_NUM_THREADS'] = '1'\n",
    "warnings.filterwarnings('ignore')\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "# import bisect\n",
    "import pickle\n",
    "import torch\n",
    "from trx_encoder import TrxEncoder\n",
    "from ptls.nn import LongformerEncoder, TransformerSeqEncoder, LongformerSeqEncoder, TabFormerFeatureEncoder, TransformerEncoder, RnnSeqEncoder, PBLinear, PBL2Norm, PBLayerNorm, Head\n",
    "from ptls.frames.bert import MLMPretrainModule\n",
    "from ptls.frames.tabformer.tabformer_module import TabformerPretrainModule\n",
    "from ptls.data_load.datasets import MemoryMapDataset\n",
    "from ptls.data_load.iterable_processing import SeqLenFilter, FeatureFilter\n",
    "from ptls.frames.supervised import SeqToTargetDataset, SequenceToTarget\n",
    "from ptls.frames import PtlsDataModule\n",
    "import torchmetrics\n",
    "from functools import partial\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "from pytorch_lightning import Trainer, seed_everything\n",
    "import pytorch_lightning as pl\n",
    "import logging\n",
    "from longformer import MLMCPCPretrainModule\n",
    "from ptls.nn import PBLinear, PBL2Norm, PBLayerNorm, PBDropout\n",
    "from ptls.frames.supervised.seq_to_target_dataset import SeqToTargetIterableDataset\n",
    "from ptls.data_load.datasets import inference_data_loader\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "308e1be9-8937-4d77-9730-a6ec34858327",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sun Mar 26 22:14:36 2023       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 525.85.12    Driver Version: 525.85.12    CUDA Version: 12.0     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA GeForce ...  Off  | 00000000:01:00.0  On |                  Off |\n",
      "|  0%   44C    P5    38W / 450W |    662MiB / 24564MiB |      8%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ac3e2044-1aed-4416-af05-210aa7d2eb23",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1 / (1 + math.exp(-x))\n",
    "\n",
    "\n",
    "def get_dataset(data):\n",
    "    return SeqToTargetDataset(\n",
    "        MemoryMapDataset(\n",
    "            data=data,\n",
    "            i_filters=[\n",
    "                FeatureFilter(keep_feature_names='target'),\n",
    "            ],\n",
    "        ),\n",
    "        target_col_name='target',\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "79f3dd18-b396-4511-b22e-825d4ce6f09d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "EMB_SIZE = 128\n",
    "PB_LINEAR = 32\n",
    "HIDDEN_SIZE = 64\n",
    "BATCH_SIZE = 32\n",
    "NUM_EPOCHS = 4\n",
    "LR = 0.01\n",
    "\n",
    "STEP_SIZE = 5\n",
    "GAMMA = 0.9\n",
    "N_SPLITS = 5\n",
    "WORD_SIZE = 300\n",
    "BIDIRECT = True\n",
    "RNN_TYPE = 'gru' #possible: 'gru', 'lstm'\n",
    "USE_TEXTS = True\n",
    "\n",
    "DATA_PATH = 'data_nn_wt.pickle'\n",
    "TARGET_PATH = \"public_train.pqt\"\n",
    "PREPROCESSOR_PATH = 'preprocessor_nn.p'\n",
    "\n",
    "target = pd.read_parquet(TARGET_PATH)\n",
    "sb = pd.read_csv(\"sample_submission.csv\")\n",
    "target = target[(target['is_male'] != 'NA') & ~(target['is_male'].isna())] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "917a939c-0d8e-41eb-95a8-c29c1f93916a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading data...\n",
      "loading data complete\n",
      "CPU times: user 3min 8s, sys: 12.9 s, total: 3min 21s\n",
      "Wall time: 3min 21s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "print(\"loading data...\")\n",
    "with open(DATA_PATH, 'rb') as handle:\n",
    "    data = pickle.load(handle)#[:1000]\n",
    "with open('words_embs.npy', 'rb') as f:\n",
    "    embs = np.load(f)\n",
    "print(\"loading data complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "542a7030-50eb-42ae-8647-f5b8c6d1fffb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "257535\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "with open('cold_users.pickle', 'rb') as handle:\n",
    "    cold_users = pickle.load(handle)\n",
    "    \n",
    "target = target[~target.user_id.isin(cold_users)]\n",
    "print(len(target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "10c84e1b-e8ce-4c43-9e2e-1f574286703f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2293"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_user_ids = target[\"user_id\"].unique()\n",
    "test_user_ids = sb[\"user_id\"].unique()\n",
    "\n",
    "dataset_train_all = [e for e in data if e[\"user_id\"] in train_user_ids]#[:100]\n",
    "dataset_test = [e for e in data if e[\"user_id\"] in test_user_ids]#[:10]\n",
    "dataset_test = sorted(dataset_test, key=lambda x: x['user_id'])\n",
    "\n",
    "df_target = target\n",
    "df_target.set_index('user_id', inplace=True)\n",
    "df_target.rename(columns={\"is_male\": \"target\"}, inplace=True)\n",
    "for el in dataset_train_all:\n",
    "    el['target'] = float(df_target['target'][el['user_id']])\n",
    "    \n",
    "del data\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d30af350-5dc0-4e09-9299-bb7d9a83f857",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "numeric_values={}\n",
    "numeric_values['price'] = 'log'\n",
    "trx_encoder_params = dict(\n",
    "    # embeddings_noise=0.005,\n",
    "    numeric_values=numeric_values,\n",
    "    embeddings={\n",
    "        'region_name': {'in': 1000, 'out': 2},\n",
    "        'city_name': {'in': 10000, 'out': 3},\n",
    "        'cpe_manufacturer_name': {'in': 1000, 'out': 2},\n",
    "        'cpe_model_name': {'in': 1000, 'out': 2},\n",
    "        'url_host': {'in': 170000, 'out': EMB_SIZE},\n",
    "        'cpe_type_cd': {'in': 10, 'out': 2},\n",
    "        'cpe_model_os_type': {'in': 100, 'out': 2},\n",
    "        'part_of_day': {'in': 10, 'out': 2},\n",
    "        'urls_topics': {'in': 300, 'out': 8},\n",
    "        'request_cnt': {'in': 100, 'out': 1},\n",
    "    },\n",
    ")\n",
    "if USE_TEXTS:\n",
    "    trx_encoder_params[\"text_value\"] = {\"in\": len(embs), \"out\": WORD_SIZE, \"weight\": embs, \"name\": \"text\"}\n",
    "trx_encoder = TrxEncoder(**trx_encoder_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "85825a1c-78ba-4ba9-999a-45d2d08d9536",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 3090 Ti') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logger.version = 47\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name          | Type              | Params\n",
      "----------------------------------------------------\n",
      "0 | seq_encoder   | RnnSeqEncoder     | 43.5 M\n",
      "1 | head          | Sequential        | 65    \n",
      "2 | loss          | BCEWithLogitsLoss | 0     \n",
      "3 | train_metrics | ModuleDict        | 0     \n",
      "4 | valid_metrics | ModuleDict        | 0     \n",
      "5 | test_metrics  | ModuleDict        | 0     \n",
      "----------------------------------------------------\n",
      "21.8 M    Trainable params\n",
      "21.6 M    Non-trainable params\n",
      "43.5 M    Total params\n",
      "173.871   Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ffbaa9ed5309460695bde88158752eda",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=4` reached.\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 3090 Ti') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "Restoring states from the checkpoint path at /app/lightning_logs/version_47/checkpoints/epoch=3-step=25756.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Loaded model weights from checkpoint at /app/lightning_logs/version_47/checkpoints/epoch=3-step=25756.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': tensor(0.5231), 'seq_len': tensor(398.1667), 'y': tensor(0.4167), 'val_loss': tensor(0.4380), 'val_BinaryAUROC': tensor(0.8794), 'train_BinaryAUROC': tensor(0.9015)}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a2305f2c47c4fd4aabe42a4972b37bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "    test_BinaryAUROC        0.8793988823890686\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using a CUDA device ('NVIDIA GeForce RTX 3090 Ti') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "133924f357fd45a2a9062c46c80e1ebf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: 6439it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using a CUDA device ('NVIDIA GeForce RTX 3090 Ti') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5783b0903caa4a98b924cf3be8daf2f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: 6439it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 2:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 3090 Ti') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name          | Type              | Params\n",
      "----------------------------------------------------\n",
      "0 | seq_encoder   | RnnSeqEncoder     | 43.5 M\n",
      "1 | head          | Sequential        | 65    \n",
      "2 | loss          | BCEWithLogitsLoss | 0     \n",
      "3 | train_metrics | ModuleDict        | 0     \n",
      "4 | valid_metrics | ModuleDict        | 0     \n",
      "5 | test_metrics  | ModuleDict        | 0     \n",
      "----------------------------------------------------\n",
      "21.8 M    Trainable params\n",
      "21.6 M    Non-trainable params\n",
      "43.5 M    Total params\n",
      "173.871   Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logger.version = 48\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "65ad894654f64ded87adc3962c32535d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=4` reached.\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 3090 Ti') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "Restoring states from the checkpoint path at /app/lightning_logs/version_48/checkpoints/epoch=1-step=12878.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Loaded model weights from checkpoint at /app/lightning_logs/version_48/checkpoints/epoch=1-step=12878.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': tensor(0.6352), 'seq_len': tensor(292.5000), 'y': tensor(0.6667), 'val_loss': tensor(0.4362), 'val_BinaryAUROC': tensor(0.8804), 'train_BinaryAUROC': tensor(0.9015)}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a20b3b71217c48cea358b9e4914cfe1b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "    test_BinaryAUROC        0.8805657029151917\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using a CUDA device ('NVIDIA GeForce RTX 3090 Ti') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ca88ef5cd7c493eafd6c7a0f2ab2186",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: 6439it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using a CUDA device ('NVIDIA GeForce RTX 3090 Ti') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b4dc442550f4d168aeeefc2d96ba69e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: 6439it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 3:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 3090 Ti') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name          | Type              | Params\n",
      "----------------------------------------------------\n",
      "0 | seq_encoder   | RnnSeqEncoder     | 43.5 M\n",
      "1 | head          | Sequential        | 65    \n",
      "2 | loss          | BCEWithLogitsLoss | 0     \n",
      "3 | train_metrics | ModuleDict        | 0     \n",
      "4 | valid_metrics | ModuleDict        | 0     \n",
      "5 | test_metrics  | ModuleDict        | 0     \n",
      "----------------------------------------------------\n",
      "21.8 M    Trainable params\n",
      "21.6 M    Non-trainable params\n",
      "43.5 M    Total params\n",
      "173.871   Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logger.version = 49\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "723973b521f644faaa0e83d1f9c8f541",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=4` reached.\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 3090 Ti') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "Restoring states from the checkpoint path at /app/lightning_logs/version_49/checkpoints/epoch=1-step=12878.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Loaded model weights from checkpoint at /app/lightning_logs/version_49/checkpoints/epoch=1-step=12878.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': tensor(0.6385), 'seq_len': tensor(312.1667), 'y': tensor(0.6667), 'val_loss': tensor(0.4402), 'val_BinaryAUROC': tensor(0.8780), 'train_BinaryAUROC': tensor(0.9021)}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6cdf207c0b4d4f6ab3cb6232a3d0aaec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "    test_BinaryAUROC         0.878201425075531\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using a CUDA device ('NVIDIA GeForce RTX 3090 Ti') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "67f7896e7cbb43229c6b0005791ab12a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: 6439it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using a CUDA device ('NVIDIA GeForce RTX 3090 Ti') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7261ec5513cb4cd4906cc1d28eb6b5e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: 6439it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 4:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 3090 Ti') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name          | Type              | Params\n",
      "----------------------------------------------------\n",
      "0 | seq_encoder   | RnnSeqEncoder     | 43.5 M\n",
      "1 | head          | Sequential        | 65    \n",
      "2 | loss          | BCEWithLogitsLoss | 0     \n",
      "3 | train_metrics | ModuleDict        | 0     \n",
      "4 | valid_metrics | ModuleDict        | 0     \n",
      "5 | test_metrics  | ModuleDict        | 0     \n",
      "----------------------------------------------------\n",
      "21.8 M    Trainable params\n",
      "21.6 M    Non-trainable params\n",
      "43.5 M    Total params\n",
      "173.871   Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logger.version = 50\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "30af3c2c51394ccc9e23d473312ee11b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=4` reached.\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 3090 Ti') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "Restoring states from the checkpoint path at /app/lightning_logs/version_50/checkpoints/epoch=3-step=25756.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Loaded model weights from checkpoint at /app/lightning_logs/version_50/checkpoints/epoch=3-step=25756.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': tensor(0.5929), 'seq_len': tensor(366.5833), 'y': tensor(0.6667), 'val_loss': tensor(0.4398), 'val_BinaryAUROC': tensor(0.8785), 'train_BinaryAUROC': tensor(0.9024)}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e45764cb13124f09ae6d21bd8347e935",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "    test_BinaryAUROC        0.8785447478294373\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using a CUDA device ('NVIDIA GeForce RTX 3090 Ti') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c07214b23f1b459eaeceb6e905ed3484",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: 6439it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using a CUDA device ('NVIDIA GeForce RTX 3090 Ti') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a5de2eb7ffd4a0cac0dc7df55331373",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: 6439it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 5:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 3090 Ti') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name          | Type              | Params\n",
      "----------------------------------------------------\n",
      "0 | seq_encoder   | RnnSeqEncoder     | 43.5 M\n",
      "1 | head          | Sequential        | 65    \n",
      "2 | loss          | BCEWithLogitsLoss | 0     \n",
      "3 | train_metrics | ModuleDict        | 0     \n",
      "4 | valid_metrics | ModuleDict        | 0     \n",
      "5 | test_metrics  | ModuleDict        | 0     \n",
      "----------------------------------------------------\n",
      "21.8 M    Trainable params\n",
      "21.6 M    Non-trainable params\n",
      "43.5 M    Total params\n",
      "173.871   Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logger.version = 51\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b420bf374ac4fc8b9d2a0c21f780ff8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=4` reached.\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 3090 Ti') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "Restoring states from the checkpoint path at /app/lightning_logs/version_51/checkpoints/epoch=0-step=6439.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Loaded model weights from checkpoint at /app/lightning_logs/version_51/checkpoints/epoch=0-step=6439.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': tensor(nan), 'seq_len': tensor(306.1667), 'y': tensor(0.6667), 'val_loss': tensor(nan), 'val_BinaryAUROC': tensor(0.5044), 'train_BinaryAUROC': tensor(0.4995)}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd99964fc3df43e2b2dd2d18c2f144e5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "    test_BinaryAUROC        0.5043914914131165\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using a CUDA device ('NVIDIA GeForce RTX 3090 Ti') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "98607488be42478298714a96ea09f4a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: 6439it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using a CUDA device ('NVIDIA GeForce RTX 3090 Ti') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "019a4efd2e4840a49888462afa7b968d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: 6439it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "skf = StratifiedKFold(n_splits=N_SPLITS)\n",
    "oof_preds = np.zeros(len(dataset_train_all))\n",
    "test_preds = np.zeros(len(dataset_test))\n",
    "\n",
    "for i, (train_index, valid_index) in enumerate(skf.split(dataset_train_all, [e['target'] for e in dataset_train_all])):\n",
    "    print(f\"Fold {i+1}:\")\n",
    "    dataset_train, dataset_valid = [dataset_train_all[i] for i in train_index], [dataset_train_all[i] for i in valid_index]\n",
    "    finetune_dm = PtlsDataModule(\n",
    "        train_data=get_dataset(dataset_train),\n",
    "        valid_data=get_dataset(dataset_valid),\n",
    "        test_data=get_dataset(dataset_test),\n",
    "        train_num_workers=1,\n",
    "        valid_num_workers=1,\n",
    "        test_num_workers=1,\n",
    "        train_batch_size=BATCH_SIZE,\n",
    "        test_batch_size=BATCH_SIZE,\n",
    "        valid_batch_size=BATCH_SIZE,\n",
    "    )\n",
    "    seed_everything(42, workers=True)\n",
    "    downstream_model = SequenceToTarget(\n",
    "        seq_encoder=RnnSeqEncoder(\n",
    "            trx_encoder=torch.nn.Sequential(\n",
    "                torch.nn.Sequential(\n",
    "                    TrxEncoder(**trx_encoder_params),\n",
    "                    PBLinear(trx_encoder.output_size + WORD_SIZE*int(USE_TEXTS == True), PB_LINEAR),\n",
    "                    PBL2Norm(),\n",
    "                ),\n",
    "                PBLayerNorm(PB_LINEAR),\n",
    "            ),\n",
    "            input_size=PB_LINEAR,\n",
    "            hidden_size=HIDDEN_SIZE,\n",
    "            bidir=BIDIRECT,\n",
    "            type=RNN_TYPE,\n",
    "        ),\n",
    "        head=torch.nn.Sequential(\n",
    "                torch.nn.Linear(HIDDEN_SIZE*(1 + int(BIDIRECT == True)), 1),\n",
    "                #torch.nn.Sigmoid(),\n",
    "                torch.nn.Flatten(start_dim=0),\n",
    "        ),\n",
    "        loss=torch.nn.BCEWithLogitsLoss(),\n",
    "        metric_list=torchmetrics.AUROC(num_classes=2, task='binary'),\n",
    "        pretrained_lr=0.005,\n",
    "        optimizer_partial=partial(torch.optim.Adam, lr=LR),\n",
    "        lr_scheduler_partial=partial(torch.optim.lr_scheduler.StepLR, step_size=1, gamma=0.1),\n",
    "    )\n",
    "\n",
    "    trainer_ft = pl.Trainer(\n",
    "        max_epochs=NUM_EPOCHS,\n",
    "        devices=1, accelerator=\"gpu\",\n",
    "        enable_progress_bar=True,\n",
    "        gradient_clip_val=1000,\n",
    "        gradient_clip_algorithm=\"norm\",\n",
    "        callbacks=[\n",
    "            pl.callbacks.LearningRateMonitor(logging_interval='step'),\n",
    "                    pl.callbacks.ModelCheckpoint(monitor=\"val_BinaryAUROC\",\n",
    "                                         mode=\"max\",\n",
    "                                         save_top_k=1),\n",
    "        ]\n",
    "    )\n",
    "    print(f'logger.version = {trainer_ft.logger.version}')\n",
    "    trainer_ft.fit(downstream_model, finetune_dm)\n",
    "    print(trainer_ft.logged_metrics)\n",
    "\n",
    "    trainer_ft.test(dataloaders=finetune_dm.val_dataloader(), verbose=True)\n",
    "\n",
    "    valid_dl = inference_data_loader(dataset_valid, num_workers=1, batch_size= BATCH_SIZE)\n",
    "    valid_preds = np.array([float(e) for e in torch.hstack(trainer_ft.predict(downstream_model, valid_dl))])\n",
    "    oof_preds[valid_index] = valid_preds\n",
    "\n",
    "    test_dl = inference_data_loader(dataset_test, num_workers=1, batch_size= BATCH_SIZE)\n",
    "    test_preds += np.array([float(e) for e in torch.hstack(trainer_ft.predict(downstream_model, test_dl))])/N_SPLITS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5ac6536d-1e7f-49e0-911c-1bd64284914f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "oof_preds1 = [sigmoid(e) for e in oof_preds]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9da87929-ac8c-4793-942b-b63340341037",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input contains NaN, infinity or a value too large for dtype('float64').",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moof roc auc: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mroc_auc_score([e[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtarget\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mfor\u001b[39;00m\u001b[38;5;250m \u001b[39me\u001b[38;5;250m \u001b[39m\u001b[38;5;129;01min\u001b[39;00m\u001b[38;5;250m \u001b[39mdataset_train_all],\u001b[38;5;250m \u001b[39moof_preds1)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;66;03m#876\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/utils/validation.py:63\u001b[0m, in \u001b[0;36m_deprecate_positional_args.<locals>._inner_deprecate_positional_args.<locals>.inner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     61\u001b[0m extra_args \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mlen\u001b[39m(all_args)\n\u001b[1;32m     62\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m extra_args \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m---> 63\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;66;03m# extra_args > 0\u001b[39;00m\n\u001b[1;32m     66\u001b[0m args_msg \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m=\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(name, arg)\n\u001b[1;32m     67\u001b[0m             \u001b[38;5;28;01mfor\u001b[39;00m name, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(kwonly_args[:extra_args],\n\u001b[1;32m     68\u001b[0m                                  args[\u001b[38;5;241m-\u001b[39mextra_args:])]\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:524\u001b[0m, in \u001b[0;36mroc_auc_score\u001b[0;34m(y_true, y_score, average, sample_weight, max_fpr, multi_class, labels)\u001b[0m\n\u001b[1;32m    522\u001b[0m y_type \u001b[38;5;241m=\u001b[39m type_of_target(y_true)\n\u001b[1;32m    523\u001b[0m y_true \u001b[38;5;241m=\u001b[39m check_array(y_true, ensure_2d\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m--> 524\u001b[0m y_score \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_score\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mensure_2d\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    526\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m y_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmulticlass\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m (y_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbinary\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[1;32m    527\u001b[0m                               y_score\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[1;32m    528\u001b[0m                               y_score\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m2\u001b[39m):\n\u001b[1;32m    529\u001b[0m     \u001b[38;5;66;03m# do not support partial ROC computation for multiclass\u001b[39;00m\n\u001b[1;32m    530\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m max_fpr \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m max_fpr \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m1.\u001b[39m:\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/utils/validation.py:63\u001b[0m, in \u001b[0;36m_deprecate_positional_args.<locals>._inner_deprecate_positional_args.<locals>.inner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     61\u001b[0m extra_args \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mlen\u001b[39m(all_args)\n\u001b[1;32m     62\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m extra_args \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m---> 63\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;66;03m# extra_args > 0\u001b[39;00m\n\u001b[1;32m     66\u001b[0m args_msg \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m=\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(name, arg)\n\u001b[1;32m     67\u001b[0m             \u001b[38;5;28;01mfor\u001b[39;00m name, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(kwonly_args[:extra_args],\n\u001b[1;32m     68\u001b[0m                                  args[\u001b[38;5;241m-\u001b[39mextra_args:])]\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/utils/validation.py:720\u001b[0m, in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)\u001b[0m\n\u001b[1;32m    716\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound array with dim \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m expected <= 2.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    717\u001b[0m                          \u001b[38;5;241m%\u001b[39m (array\u001b[38;5;241m.\u001b[39mndim, estimator_name))\n\u001b[1;32m    719\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m force_all_finite:\n\u001b[0;32m--> 720\u001b[0m         \u001b[43m_assert_all_finite\u001b[49m\u001b[43m(\u001b[49m\u001b[43marray\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    721\u001b[0m \u001b[43m                           \u001b[49m\u001b[43mallow_nan\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_all_finite\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mallow-nan\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    723\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ensure_min_samples \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    724\u001b[0m     n_samples \u001b[38;5;241m=\u001b[39m _num_samples(array)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/utils/validation.py:103\u001b[0m, in \u001b[0;36m_assert_all_finite\u001b[0;34m(X, allow_nan, msg_dtype)\u001b[0m\n\u001b[1;32m    100\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (allow_nan \u001b[38;5;129;01mand\u001b[39;00m np\u001b[38;5;241m.\u001b[39misinf(X)\u001b[38;5;241m.\u001b[39many() \u001b[38;5;129;01mor\u001b[39;00m\n\u001b[1;32m    101\u001b[0m             \u001b[38;5;129;01mnot\u001b[39;00m allow_nan \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m np\u001b[38;5;241m.\u001b[39misfinite(X)\u001b[38;5;241m.\u001b[39mall()):\n\u001b[1;32m    102\u001b[0m         type_err \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124minfinity\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m allow_nan \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNaN, infinity\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m--> 103\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    104\u001b[0m                 msg_err\u001b[38;5;241m.\u001b[39mformat\n\u001b[1;32m    105\u001b[0m                 (type_err,\n\u001b[1;32m    106\u001b[0m                  msg_dtype \u001b[38;5;28;01mif\u001b[39;00m msg_dtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m X\u001b[38;5;241m.\u001b[39mdtype)\n\u001b[1;32m    107\u001b[0m         )\n\u001b[1;32m    108\u001b[0m \u001b[38;5;66;03m# for object dtype data, we only check for NaNs (GH-13254)\u001b[39;00m\n\u001b[1;32m    109\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m X\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m np\u001b[38;5;241m.\u001b[39mdtype(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mobject\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m allow_nan:\n",
      "\u001b[0;31mValueError\u001b[0m: Input contains NaN, infinity or a value too large for dtype('float64')."
     ]
    }
   ],
   "source": [
    "print(f\"oof roc auc: {roc_auc_score([e['target'] for e in dataset_train_all], oof_preds1)}\") #876"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bd49fa3-5c2c-4347-b0cb-735e9beb3435",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pred_test_nn = pd.DataFrame()\n",
    "pred_test_nn[\"is_male\"] = test_preds\n",
    "pred_test_nn['is_male'] = pred_test_nn['is_male'].apply(lambda x: sigmoid(x))\n",
    "pred_test_nn[\"user_id\"] = [e[\"user_id\"] for e in dataset_test]\n",
    "pred_test_nn.sort_values(\"user_id\", inplace=True)\n",
    "pred_test_nn.to_csv(\"ismale_rnn_test.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c9d63f9-bf3b-4f90-b3fd-5a35bb9a953c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pred_oof_nn = pd.DataFrame()\n",
    "pred_oof_nn[\"is_male\"] = oof_preds1\n",
    "pred_oof_nn[\"user_id\"] = [e[\"user_id\"] for e in dataset_train_all]\n",
    "pred_oof_nn.sort_values(\"user_id\", inplace=True)\n",
    "pred_oof_nn.to_csv(\"ismale_rnn_oof.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ea8f295-8777-4eb9-9a09-a430aa7de17a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
